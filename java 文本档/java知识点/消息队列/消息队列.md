# 消息队列

## 1.为什么使用消息队列？

​     优点： 解耦，异步，削峰。

缺点：

   系统可用性降低

   系统复杂度提高

   一致性问题

**Kafka，ActiveMQ，RabbitMQ，RocketMQ有什么优缺点？**

| 特性                    | ActiveMQ                             | RabbitMQ                                         | RocketMQ                                                     | Ksfka                                                        |
| ----------------------- | ------------------------------------ | ------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量              | 万级，比RocketMQ，Kafaka低一个数量级 | 同ActiveMQ                                       | 10万级，支撑高吞吐量                                         | 10万级，高吞吐，一般配合大数据类的系统来进行实时数据计算，日志采集等场景。 |
| topic数量对吞吐量的影响 |                                      |                                                  | topic可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic | topic从几十到几百个的时候，吞吐量会大幅度下降，在同等机器下，kafka尽量保证topic数量不要过多，如果需要支撑大规模的topic，需要增加更多的机器资源 |
| 时效性                  | （毫秒）ms级                         | 微秒级，这是RabbitMQ的一大特点，延迟最低         | ms级                                                         | 延迟在ms级以内                                               |
| 可用性                  | 高，基于主从架构实现高可用           | 同ActiveMQ                                       | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性              | 有较低的概率丢失数据                 | 基本不丢                                         | 经过参数优化设置，可以做到0丢失                              | 同RocketMQ                                                   |
| 功能支持                | MQ领域的功能极其完备                 | 基于erlang开发，并发能力很强，性能极好，延时很低 | MQ功能较为完善，还是分布式的，扩展性好                       | 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用 |

## 消息中间件的高可用？

### RabbitMQ的高可用性

​      RabbitMQ是比较有代表性的，因为是**基于主从**（非分布式）做高可用的。

​      RabbitMQ有三种模式：单机模式，普通集群模式，镜像集群模式。

**单例模式**：

​    就是Demo级别的。

**普通集群模式（无高可用性）**

​    普通集群模式，意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。你创建的queue，只会放在一个RabbitMQ实例上，但是每个实例都同步queue的元数据（元数据可以认为是queue的一些配置信息，通过元数据，可以找到queue所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么实例会从queue所在实例上拉取数据过来。

![mq-7.png](https://github.com/doocs/advanced-java/blob/master/images/mq-7.png?raw=true)

这种方式确实很麻烦，也不怎么好，**没做到所谓的分布式**，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在的实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**。

而且如果这个那个放在queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让RabbitMQ落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。

所以这里没有什么所谓的高可用性，这方案主要是提高吞吐量的。就是说让集群中多个节点来服务某个queue的读写操作。

**镜像集群模式（高可用性）**

​     这种模式，才是所谓的RabbitMQ的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的queue，无论元数据还是queue里面的消息都会存在于多个实例上，就是说，每个RabbitMQ节点都有这个queue的一个完整镜像，包含queue的全部数据的意思。然后每次你写消息到queue的时候，都会自动把消息同步到多个实例的queue上。

![mq-8.png](https://github.com/doocs/advanced-java/blob/master/images/mq-8.png?raw=true)

那么**如何开启这个镜像集群模式呢**？RabbitMQ的管理控制台可以新增一个**镜像集群模式的策略**，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建queue的时候，应用这个策略，就会自动将数据同步到其他节点上去了。

优点在于任何一个机器宕机了，其他的机器节点还包含这个queue的完整数据。

缺点在于性能开销太大，消息需要同步到所有的机器上，导致网络带宽压力和消耗很重。这种方式也不是分布式，没有扩展性可言，如果某个queue负载很重，所有的机器均是负载很重的数据，并没有办法线性扩展你的queue。

### Kafka的高可用性

Kafka架构的认识：由多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。

这就是**天然的分布式消息队列**，就是说一个topic的数据，**是分散放在多个机器上的，每个机器就放一部分的数据。**

实际上RabbitMQ之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群，HA（High Availbility，高可用性）的机制而已，RabbitMQ一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。

Kafka0.8之前，是没有的HA机制的，就是任何一个broker宕机了，那个broker上的partition就无效了，不能再进行读写。

一开始的版本比如说：我们创建了一个topic，指定它的partition是3个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个topic的1/3的数据就丢了，因此这个是做不到高可用的。



![kafka-before.png](https://github.com/doocs/advanced-java/blob/master/images/kafka-before.png?raw=true)

后续加强的版本。提供了HA机制，就是replica（复制品）副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。所有的replica会选举一个leader出来，那么生产和消费都会跟这个leader进行沟通，然后生产或消费的操作会同步到各个follower，读的时候就直接leader上的数据即可，Kafka会因为害怕系统复杂度过高导致出现问题，而均匀地将一个partition的所有副本分布到不同的机器上，这样才可以提高容错性。

![kafka-after.png](https://github.com/doocs/advanced-java/blob/master/images/kafka-after.png?raw=true)

这样也就是所谓的高可用性，因为某个broker宕机了，会重新在follower中再次选举出leader进行操作。

写数据的时候。生产者就写leader，然后leader将数据落地写成本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。

消费的时候，只会从leader去读，但是只有当一个消息已经被所有follower都同步返回ack的时候，这个消息才会被消费者读到。

## 消息中间的问题剖析

### RabbitMQ

![rabbitmq-message-lose.png](https://github.com/doocs/advanced-java/blob/master/images/rabbitmq-message-lose.png?raw=true)

**生产者弄丢了数据**

生产者将数据发送到RabbitMQ的时候，可能数据就在半路上丢失。

一是RabbitMQ事务机制（同步），但是吞吐量会下降，但是太耗性能。

```
// 开启事务
channel.txSelect
try {
    // 这里发送消息
} catch (Exception e) {
    channel.txRollback

    // 这里再次重发这条消息
}

// 提交事务
channel.txCommit
```

二是confirm机制（异步），在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

事务机制和 `confirm` 机制最大的不同在于，**事务机制是同步的**，你提交一个事务之后会**阻塞**在那儿，但是 `confirm` 机制是**异步**的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。

所以一般在生产者这块**避免数据丢失**，都是用 `confirm` 机制的。

**RabbitMQ弄丢了数据**

就是 RabbitMQ 自己弄丢了数据，这个你必须**开启 RabbitMQ 的持久化**，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，**恢复之后会自动读取之前存储的数据**，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，**可能导致少量数据丢失**，但是这个概率较小。

设置持久化有**两个步骤**：

- 创建 queue 的时候将其设置为持久化
  这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。
- 第二个是发送消息的时候将消息的 `deliveryMode` 设置为 2
  就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。

必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。

注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。

所以，持久化可以跟生产者那边的 `confirm` 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 `ack` 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack`，你也是可以自己重发的。

**消费端弄丢了数据**

RabbitMQ 如果丢失了数据，主要是因为你消费的时候，**刚消费到，还没处理，结果进程挂了**，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。

这个时候得用 RabbitMQ 提供的 `ack` 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 `ack`，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。这样的话，如果你还没处理完，不就没有 `ack` 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

![rabbitmq-message-lose-solution.png](https://github.com/doocs/advanced-java/blob/master/images/rabbitmq-message-lose-solution.png?raw=true)

### Kafka

#### 消费端弄丢了数据

唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边**自动提交了 offset**，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。

这不是跟 RabbitMQ 差不多吗，大家都知道 Kafka 会自动提交 offset，那么只要**关闭自动提交** offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是**可能会有重复消费**，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。

生产环境碰到的一个问题，就是说我们的 Kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了。

#### Kafka 弄丢了数据

这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。

生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。

所以此时一般是要求起码设置如下 4 个参数：

- 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
- 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
- 在 producer 端设置 `acks=all`：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。
- 在 producer 端设置 `retries=MAX`（很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**，卡在这里了。

我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。

#### 生产者会不会弄丢数据？

如果按照上述的思路设置了 `acks=all`，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

### 如何保证消息不被重复消费？何为幂等性？

**幂等性**：通俗点来说，就是一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。

保证消息不被重复消费就是需要保证其的幂等性，有以下思路：

​      1.比如你拿个数据要存入库，可以先根据主键进行查询看数据是否已存在，若已存在则更新一下。

​      2.但是如果你是写入缓存Redis中就不需要做任何操作了。

​      3.但是前者两个场景都不是，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费之后，先根据id去比如Redis查询一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写Redis，如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。

​       4.比如基于数据库的唯一键来保证重复插入多条，因为有唯一键约束了，重复数据插入只会报错，不会导致数据中出现脏数据。

![mq-11](https://github.com/doocs/advanced-java/raw/master/images/mq-11.png)

### 如何保存消息的顺序性？

**RabbitMQ**

一拆分多个queue，每个queue一个consumer，就是多一些queue而已。

二是就一个queue但是对应一个consumer，然后consumer内部用内存队列排队，然后分发给底层不同的worker来处理。

![rabbitmq-order-02](https://github.com/doocs/advanced-java/raw/master/images/rabbitmq-order-02.png)

**Kafka**

​    1.一个topic，一个partition，一个consumer，内部单线程消费，单线吞吐量太低，一般不会用这个。

​    2.写N个内存queue，具有相同key的数据都到同一个内存queue；然后对于N个线程，每个线程分别消费一个queue即可，这样就可以保证顺序性。

![kafka-order-02](https://github.com/doocs/advanced-java/raw/master/images/kafka-order-02.png)

### 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时？

#### **大量消息在mq里积压几个小时的解决方案：**

​     1.先修复consumer的问题，确保其恢复消费速度，然后将现有的consumer都停掉。

​     2.新建一个topic，partition是原来的10倍，临时建立好原先10倍的queue数量。

​     3.然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理，**直接均匀轮询写入临时建立好的10倍数量的queue。

​     4.接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据。这种做法相当于临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据。

​     5.等快速消费完积压数据之后，**得恢复原先部署的架构，重新**用原先的consumer机器来消费消息。

#### mq中的消息过期失效了

​     假设你用的是RabbitMQ，RabbitMQ是可以设置过期时间的，也就是TTL。如果消息在queue中积压超过一定时间就会被清理掉，就会出现**大量数据直接丢失。**

​      解决·方案就是批量重导，在大量积压的时候，直接丢数据，后续将数据找回并重新导入。

#### mq快写满了

​     如果消息积压在mq里，你很长时间都没有处理掉，此时导致mq都快写满了，咋办？这个还有别的方法嘛？没有，谁让你第一个方案执行的太慢了，临时写程序，接入数据消费，**消费一个丢弃一个，都不要了，**快速消费掉所有的消息，然后在进行批量重导。

### 如何设计消息队列的架构？

```
首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？

其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。

其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。

能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。
```

